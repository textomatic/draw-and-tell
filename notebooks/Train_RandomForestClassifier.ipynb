{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a03ffb-c9e1-47c2-980c-ca69e65ca7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb2af263-d255-4e86-98ea-1fcb8e7aa58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "_ANIMAL_CLASS_FILE = 'animal_classes.txt'\n",
    "_DATA_PATH = '../data/train_simplified'\n",
    "_IMAGE_SIZE = 64\n",
    "_TRAIN_ROWS_PER_CLASS = 1000\n",
    "_TEST_ROWS_PER_CLASS = 200\n",
    "_DATALOADER_BATCH_SIZE = 16\n",
    "_DATALOADER_NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2934bf00-16ab-46e6-8047-2a77d5dd1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodlesDataset(Dataset):\n",
    "    \"\"\"Custom class for the Quick! Draw It doodles dataset\"\"\"\n",
    "\n",
    "    # Class variable of doodle image default size\n",
    "    doodle_base_size = 256\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, encoding_dict, num_rows=1000, skip_rows=None, size=256, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file(str): Path to the CSV file containing doodle data\n",
    "            root_dir(str): Path to root directory containing all the doodles data files\n",
    "            num_rows(int): Number of rows of the CSV file to read\n",
    "            skip_rows(int): Number of rows to skip from the beginning of the CSV file\n",
    "            size(int): Size of output image\n",
    "            transform(torchvision.transforms): Torchvision transformations to be applied on a doodle, defaults to None\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.size = size\n",
    "        self.doodle = pd.read_csv(os.path.join(self.root_dir, csv_file), usecols=['drawing'], nrows=num_rows, skiprows=skip_rows)\n",
    "        self.transform = transform\n",
    "        self.label = get_label(encoding_dict, csv_file)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _draw(raw_strokes, size=256, line_weight=6, time_color=False):\n",
    "        \"\"\"\n",
    "        Draws the doodle using OpenCV line function and resizes it to specified size if necessary.\n",
    "\n",
    "        Args:\n",
    "            raw_strokes(List[List[List[int], List[int]]]: Nested lists representing doodle strokes in sequence, where the outermost list represent a stroke, the first innermost list represents X displacement of each point, and the second innermost list represents Y displacement of each point\n",
    "            size(int): Size of the doodle to be drawn\n",
    "            line_weight(int): Size of the line\n",
    "            time_color(bool): Shows stroke of varying color as a function of time, defaults to False\n",
    "\n",
    "        Returns:\n",
    "            img(np.ndarray): Numpy array representing the doodle\n",
    "        \"\"\"\n",
    "        # Initialize doodle as empty numpy matrix\n",
    "        img = np.zeros((DoodlesDataset.doodle_base_size, DoodlesDataset.doodle_base_size), np.uint8)\n",
    "\n",
    "        # Draw doodle according to sequence of strokes\n",
    "        for t, stroke in enumerate(raw_strokes):\n",
    "            for i in range(len(stroke[0]) - 1):\n",
    "                color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "                _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                             (stroke[0][i + 1], stroke[1][i + 1]), color, line_weight)\n",
    "        \n",
    "        # Resize doodle if applicable\n",
    "        if size != DoodlesDataset.doodle_base_size:\n",
    "            img = cv2.resize(img, (size, size))\n",
    "        \n",
    "        return img\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns size of the dataset\"\"\"\n",
    "        return len(self.doodle)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Gets one doodle and its label by index.\n",
    "\n",
    "        Args:\n",
    "            index(int): Index representing target row in doodle dataset to access\n",
    "        \n",
    "        Returns:        \n",
    "            (np.ndarray): Numpy array representing the doodle\n",
    "            (int): Numerically encoded label of the doodle\n",
    "        \"\"\"\n",
    "        # Perform literal evaluation of string to obtain raw strokes\n",
    "        raw_strokes = ast.literal_eval(self.doodle.drawing[index])\n",
    "\n",
    "        # Call static draw method to get doodle drawn\n",
    "        doodle = self._draw(raw_strokes, size=self.size, line_weight=2)\n",
    "\n",
    "        # Apply transformations on doodle if applicable\n",
    "        if self.transform:\n",
    "            doodle = self.transform(doodle)\n",
    "        \n",
    "        return (doodle[None]/255).astype('float32'), self.label\n",
    "\n",
    "\n",
    "def decode_labels(dec_dict, label):\n",
    "    \"\"\"\n",
    "    Obtains the class label (string) represented by the given numerically encoded label.\n",
    "\n",
    "    Args:\n",
    "        dec_dict(dict[int, str]): Dictionary containing the numerically encoded label and their corresponding class label\n",
    "        label(int): Numerical encoded label \n",
    "\n",
    "    Returns:\n",
    "        (str): Class label corresponding to the encoded label\n",
    "    \"\"\"\n",
    "    return dec_dict[label]\n",
    "\n",
    "\n",
    "def get_label(encoding_dict, filename):\n",
    "    \"\"\"\n",
    "    Obtains the numerically encoded label of a class given a CSV file of doodle data.\n",
    "\n",
    "    Args:\n",
    "        encoding_dict(dict[str, int]): Dictionary containing the class label and their corresponding numerically encoded label\n",
    "        filename(str): Path to a CSV file containing doodle data\n",
    "    \n",
    "    Returns:\n",
    "        (int): Numerically encoded label of a class\n",
    "    \"\"\"\n",
    "    return encoding_dict[filename[:-4].split('/')[-1].replace(' ', '_')]\n",
    "\n",
    "def load_classes(filename):\n",
    "    \"\"\"\n",
    "    Loads the class labels from a text file.\n",
    "    \n",
    "    Args:\n",
    "        filename(str): Path to the text file containing class labels\n",
    "\n",
    "    Returns:\n",
    "        classes(List[str]): List containing all class labels\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        classes = f.read()\n",
    "    return classes.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e557af5-d78d-46cb-917f-0d69c6990486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(animal_list):\n",
    "    \"\"\"\n",
    "    Prepares dataset as dataloaders and adds transformations to them.\n",
    "\n",
    "    Args:\n",
    "        animal_list(List[str]): List containing all class labels\n",
    "\n",
    "    Returns:\n",
    "        encoding_dict(dict[str, int]): Dictionary containing the class label and their corresponding encoding number \n",
    "        dataloaders(dict[str, torch.utils.data.DataLoader]): Dictionary containing the train and test dataloaders\n",
    "        dataset_sizes(dict[str, int]): Dictionary containing the sizes of train and test datasets\n",
    "    \"\"\"\n",
    "    # Get all the CSV files containing doodle data\n",
    "    filenames = glob.glob(os.path.join(_DATA_PATH, '*.csv'))\n",
    "\n",
    "    # Filter classes to only those in animal_list\n",
    "    filtered_filenames = []\n",
    "    for file in filenames:\n",
    "        if file.split('/')[-1].split('.')[0].replace(' ', '_') in animal_list:\n",
    "            filtered_filenames.append(file)\n",
    "    \n",
    "    # Initialize dictionary to encode label with numbers\n",
    "    encoding_dict = {}\n",
    "    counter = 0\n",
    "    for fn in filtered_filenames:\n",
    "        encoding_dict[fn[:-4].split('/')[-1].replace(' ', '_')] = counter\n",
    "        counter += 1\n",
    "    \n",
    "    # Create an inverted dictionary for decoding number to label\n",
    "    decoding_dict = {v: k for k , v in encoding_dict.items()}\n",
    "    \n",
    "    # Create train set by concatenating dataset from all classes\n",
    "    train_set = ConcatDataset([DoodlesDataset(fn.split('/')[-1], _DATA_PATH, encoding_dict, num_rows=_TRAIN_ROWS_PER_CLASS, size=_IMAGE_SIZE) for fn in filtered_filenames])\n",
    "    \n",
    "    # Create test set by concatenating dataset from all classes\n",
    "    test_set = ConcatDataset([DoodlesDataset(fn.split('/')[-1], _DATA_PATH, encoding_dict, num_rows=_TEST_ROWS_PER_CLASS, size=_IMAGE_SIZE, skip_rows=range(1, _TRAIN_ROWS_PER_CLASS+1)) for fn in filtered_filenames])\n",
    "\n",
    "    return encoding_dict, decoding_dict, train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb40bad2-5554-471a-9ed3-48eee300b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classes\n",
    "animal_list = load_classes(_ANIMAL_CLASS_FILE)\n",
    "\n",
    "# Prepare data\n",
    "encoding_dict, decoding_dict, train_set, test_set = prepare_data(animal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d110dee-a8f5-4907-a823-e6bde64dc88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5533cd6-6565-428e-bfb5-d2ebb25955a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for data in train_set:\n",
    "    inputs, labels = data\n",
    "    images = inputs.reshape(-1)\n",
    "    train_data.append(images)\n",
    "    train_labels.append([labels])\n",
    "\n",
    "train_data=np.array(train_data)\n",
    "train_labels=np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cf9ffd7-616e-410e-9f29-dbec034a6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for data in test_set:\n",
    "    inputs, labels = data\n",
    "    images = inputs.reshape(-1)\n",
    "    test_data.append(images)\n",
    "    test_labels.append([labels])\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3303796d-52ea-43e2-90e4-cb9f123b6572",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-6471998b8876>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  m.fit(train_data, train_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models:  <class 'sklearn.ensemble._forest.RandomForestClassifier'> , Accuracy:  0.1814705882352941\n",
      "Models:  <class 'sklearn.tree._classes.DecisionTreeClassifier'> , Accuracy:  0.06754901960784314\n",
      "The best model is <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "models = [RandomForestClassifier(random_state=45), DecisionTreeClassifier(random_state=0)]\n",
    "results= []\n",
    "\n",
    "for m in models:\n",
    "    m.fit(train_data, train_labels)\n",
    "    predictions = m.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    print(\"Models: \", type(m),\", Accuracy: \", accuracy)\n",
    "    results.append(accuracy)\n",
    "\n",
    "best_model = models[np.argmax(results)]\n",
    "print(\"The best model is\", type(best_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipi540_finalproject_cv",
   "language": "python",
   "name": "aipi540_finalproject_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
